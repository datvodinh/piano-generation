vocab_size: 416
d_model: 512
nlayers: 2
batch_first: true
lr: 0.0002
max_lr: 0.0006
beta: [0.9, 0.999]
total_steps: 500_000
pct_start: 0.1
model_type: lstm